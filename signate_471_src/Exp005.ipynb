{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Exp005.ipynb","provenance":[{"file_id":"14buLHzwACALiMi8dqkgFhlo3DFBtP2eS","timestamp":1629043489149}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2f36214382834a1588cdfa5584560e45":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e5e4b40deea54c208979380bef5a9239","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0b032a29679441b59694fb6f57916140","IPY_MODEL_39b5dd4482b046eab919475046546178","IPY_MODEL_2a14e629293c4ab4a290a47fae5d9ae9"]}},"e5e4b40deea54c208979380bef5a9239":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b032a29679441b59694fb6f57916140":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67ae6613a8894106bde55bbd4c1e19a6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_beb2457c5ecb421eafa8c4a6e854e716"}},"39b5dd4482b046eab919475046546178":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_06c000efc5834fa29f537992bcb1572f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13d7fa0921c7465eab624d5cf0d0d881"}},"2a14e629293c4ab4a290a47fae5d9ae9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_97a3c191e7a840f6a495709fe0bb0b76","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 1.32MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_474279bb58fe4f30afdb7aebd4ae8b39"}},"67ae6613a8894106bde55bbd4c1e19a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"beb2457c5ecb421eafa8c4a6e854e716":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"06c000efc5834fa29f537992bcb1572f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"13d7fa0921c7465eab624d5cf0d0d881":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97a3c191e7a840f6a495709fe0bb0b76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"474279bb58fe4f30afdb7aebd4ae8b39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d2078a8053c4def8d3d1b1d7ec6c8b9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_25b8d14f096a42faaad75c0eeb5a9850","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_041d817fd54b4807b3a393b6ed514f62","IPY_MODEL_23b9344e14194ce38ac2907aa45e856f","IPY_MODEL_d2eb195d22f9427688713d01518242ce"]}},"25b8d14f096a42faaad75c0eeb5a9850":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"041d817fd54b4807b3a393b6ed514f62":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a1867ca9e60543a2bfce2002a9106923","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79f3977111e745ae9e853e862345cdc9"}},"23b9344e14194ce38ac2907aa45e856f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c913241dce8d4594b169f7619b18858f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":313,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":313,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_75c844118ec741c99d7c6d7d647f443e"}},"d2eb195d22f9427688713d01518242ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b5d9417fb06642fc82b4df43c0050ea0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 313/313 [00:00&lt;00:00, 11.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_594c7595285d4bfeab63ad4db21e0af2"}},"a1867ca9e60543a2bfce2002a9106923":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79f3977111e745ae9e853e862345cdc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c913241dce8d4594b169f7619b18858f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"75c844118ec741c99d7c6d7d647f443e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5d9417fb06642fc82b4df43c0050ea0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"594c7595285d4bfeab63ad4db21e0af2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e0e776ce6b14813b78d5be5ec4767ec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6bf5b7560b584b8ca8251f48606e92c6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a7fa7cee9d5a4892bc89df6f0557f327","IPY_MODEL_ded97e23635746db8cc43a4633289774","IPY_MODEL_51da5525d4434dc0ba63f70223a2a8ed"]}},"6bf5b7560b584b8ca8251f48606e92c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7fa7cee9d5a4892bc89df6f0557f327":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2711dd85706e484c9faf9f94ffdf2c47","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74c6e9beed824f80ade9f88b0ca98366"}},"ded97e23635746db8cc43a4633289774":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fef611aa515e4908bf9b58a25daae964","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":440512265,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440512265,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_932fadd1a9b649f9bc306b390a373496"}},"51da5525d4434dc0ba63f70223a2a8ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b2353821e5d04be994023c01ed6c2a9f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 441M/441M [00:07&lt;00:00, 59.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2876de029b7440ff926f0a3cac2f11c0"}},"2711dd85706e484c9faf9f94ffdf2c47":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"74c6e9beed824f80ade9f88b0ca98366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fef611aa515e4908bf9b58a25daae964":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"932fadd1a9b649f9bc306b390a373496":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b2353821e5d04be994023c01ed6c2a9f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2876de029b7440ff926f0a3cac2f11c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"JXepDb7__Oml"},"source":["## Exp-005 (Blue BERT)\n","\n","BlueBERT-Base, Uncased, PubMed+MIMIC-III\n","論文ではこれが一番精度高い。\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sa2hpabgm7vJ","executionInfo":{"status":"ok","timestamp":1629241835376,"user_tz":-540,"elapsed":19076,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"c43beff6-9ba3-45ff-e664-41bde117131e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKlEabxO_MSm","executionInfo":{"status":"ok","timestamp":1629241837726,"user_tz":-540,"elapsed":493,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"c7742846-5df8-49cc-993b-31e05033360d"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Tue Aug 17 23:10:37 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vE7GdrrE_dev","executionInfo":{"status":"ok","timestamp":1629241868977,"user_tz":-540,"elapsed":27431,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"6296e6fe-1c77-440f-b5f4-7ac71212daa0"},"source":["!pip install transformers pycld2"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 13.3 MB/s \n","\u001b[?25hCollecting pycld2\n","  Downloading pycld2-0.41.tar.gz (41.4 MB)\n","\u001b[K     |████████████████████████████████| 41.4 MB 67 kB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 79.9 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 86.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 79.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Building wheels for collected packages: pycld2\n","  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834307 sha256=057dddc8552516c156533d0d08797b7711e248146c0ef4bcad97c6e3ac827a75\n","  Stored in directory: /root/.cache/pip/wheels/ed/e4/58/ed2e9f43c07d617cc81fe7aff0fc6e42b16c9cf6afe960b614\n","Successfully built pycld2\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, pycld2\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pycld2-0.41 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O3gDMmLR_oJ3","executionInfo":{"status":"ok","timestamp":1629241868977,"user_tz":-540,"elapsed":22,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["input_dir = \"/content/drive/MyDrive/07_Competition/signate-471/data/\"\n","output_dir = \"/content/drive/MyDrive/07_Competition/signate-471/log/\"\n","submission_dir = \"/content/drive/MyDrive/07_Competition/signate-471/submission/\"\n","model_dir = \"/content/drive/MyDrive/07_Competition/signate-471/model_bin/\"\n","pred_dir = \"/content/drive/MyDrive/07_Competition/signate-471/pred/\""],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88KVneP6_o1Z","executionInfo":{"status":"ok","timestamp":1629241874693,"user_tz":-540,"elapsed":5735,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"6a2b715d-8d23-4c73-c75e-0bf02f821144"},"source":["import os\n","import math\n","import random\n","import pandas as pd\n","import numpy as np\n","from glob import glob\n","import gc\n","gc.enable()\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.optim as optim\n","from torch.optim.optimizer import Optimizer\n","import torch.optim.lr_scheduler as lr_scheduler\n","from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import fbeta_score\n","\n","from transformers import BertConfig, RobertaConfig\n","from transformers import (get_cosine_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup)\n","from transformers import BertTokenizer, RobertaTokenizer\n","from transformers import BertModel, RobertaModel\n","from transformers import AutoConfig, BertConfig, RobertaConfig\n","from transformers import BertForSequenceClassification, RobertaForSequenceClassification\n","from torch import cuda\n","import time\n","\n","from transformers import AdamW\n","from transformers import AutoTokenizer\n","from transformers import AutoModel, AutoModelForSequenceClassification\n","from transformers import MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\n","from transformers import get_linear_schedule_with_warmup\n","\n","from IPython.display import clear_output\n","from tqdm import tqdm, trange\n","\n","import re\n","import nltk\n","import pycld2 as cld2\n","from scipy.optimize import minimize, minimize_scalar\n","import regex\n","nltk.download('stopwords')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"slgK2kwa_tdt","executionInfo":{"status":"ok","timestamp":1629241874694,"user_tz":-540,"elapsed":3,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["class CFG:\n","  exp = \"exp05\"\n","  seed = 71\n","  fold = 5\n","  max_len = 280\n","  epochs = 1\n","  lr = 2e-5\n","  train_batch_size = 16\n","  valid_batch_size = 32\n","  model_name = \"bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12\"\n","\n","CONFIG = CFG()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWMPal_oAmmz","executionInfo":{"status":"ok","timestamp":1629241875952,"user_tz":-540,"elapsed":1261,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["os.makedirs(model_dir+CONFIG.exp+\"/\", exist_ok=True)\n","os.makedirs(pred_dir+CONFIG.exp+\"/\", exist_ok=True)\n","os.makedirs(output_dir+CONFIG.exp+\"/\", exist_ok=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_d2AXNBAkKu","executionInfo":{"status":"ok","timestamp":1629241875954,"user_tz":-540,"elapsed":3,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True\n","\n","set_random_seed(CONFIG.seed)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"n47LBGkly0mL","executionInfo":{"status":"ok","timestamp":1629241875955,"user_tz":-540,"elapsed":3,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["DEVICE = torch.device('cuda') if cuda.is_available() else 'cpu'"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"em7TEBclApr_","executionInfo":{"status":"ok","timestamp":1629241876442,"user_tz":-540,"elapsed":490,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["def init_logger(log_file=output_dir + CONFIG.exp+ f\"/{CONFIG.exp}_train.log\"):\n","    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n","\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = init_logger()"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOh95cXMAxta","executionInfo":{"status":"ok","timestamp":1629241876442,"user_tz":-540,"elapsed":15,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["def get_train_data(train):\n","    # 交差検証 用の番号を振ります。\n","    Fold = StratifiedKFold(n_splits=CONFIG.fold, shuffle=True, random_state=CONFIG.seed)\n","    for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"judgement\"])):\n","        train.loc[val_index, \"fold\"] = int(n)\n","    train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n","\n","    return train\n","\n","def get_test_data(test):\n","    return test"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"5V4URD_dAY2t","executionInfo":{"status":"ok","timestamp":1629241876443,"user_tz":-540,"elapsed":16,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["class SRWSDataset(Dataset):\n","  def __init__(self, df, inference_only=False):\n","\n","    # Berttokenizer\n","    tokenizer = BertTokenizer.from_pretrained(CONFIG.model_name)\n","\n","    self.df = df\n","    self.inference_only = inference_only # \"train\":False or \"test\":True\n","    self.text = self.df[\"title_abst\"].tolist() # text\n","\n","    if not self.inference_only:\n","      # ここvalueだけ\n","      self.target = df[\"judgement\"].values\n","      \n","    self.encoded = tokenizer.batch_encode_plus(\n","        self.text,\n","        padding = \"max_length\",\n","        max_length = CONFIG.max_len,\n","        truncation = True,\n","        return_attention_mask=True\n","    )\n","\n","  def __len__(self):\n","    return len(self.df)\n","\n","  def __getitem__(self, index):\n","    input_ids = torch.tensor(self.encoded[\"input_ids\"][index])\n","    attention_mask = torch.tensor(self.encoded[\"attention_mask\"][index])\n","\n","    # returnをsetかdictで返すかは自由\n","    if self.inference_only:\n","      return (input_ids, attention_mask)\n","\n","    else:\n","      # ここで、tensor に変更している\n","      target = torch.tensor(self.target[index]).float()\n","      return (input_ids, attention_mask, target)\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EdX0AIdEAw7","executionInfo":{"status":"ok","timestamp":1629241876443,"user_tz":-540,"elapsed":15,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["class SRWSBertModel(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    # config を設定することで、元の設定を変更できる？\n","    # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/260729\n","    # 最終的にsigmoidに通すから、num_labelsは1でいい\n","    self.bert = BertForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=1)\n","    # この辺を調整することで、モデル内の最終層に追加することができる。\n","    # bertのoutputがclassificationなんで、そこを変更しないと\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, input_ids, attention_mask):\n","    bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask) \n","    bert_output = self.sigmoid(bert_output.logits).squeeze()\n","\n","    return bert_output"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hB8VYTNW1MJc","executionInfo":{"status":"ok","timestamp":1629241876443,"user_tz":-540,"elapsed":15,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"b76ASi80wKMA","executionInfo":{"status":"ok","timestamp":1629241876443,"user_tz":-540,"elapsed":15,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["# 学習\n","def train_fn(model, train_loader, optimizer, epoch, loss_function, scheduler=None):\n","  start = end = time.time()\n","  losses = AverageMeter()\n","  model.train()\n","\n","  for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","\n","    input_ids = input_ids.to(DEVICE)\n","    attention_mask = attention_mask.to(DEVICE)\n","    target = target.to(DEVICE)\n","    batch_size = target.size(0)\n","\n","    pred = model(input_ids, attention_mask)\n","\n","    # Loss算出\n","    loss = loss_function(pred, target)\n","    losses.update(loss.item(), batch_size)\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if scheduler:\n","      scheduler.step()\n","\n","    if batch_num % 100 == 0 or batch_num == (len(train_loader) -1):\n","      print(\n","            f\"Epoch: [{epoch + 1}][{batch_num}/{len(train_loader)}] \"\n","            f\"Elapsed {timeSince(start, float(batch_num + 1) / len(train_loader)):s} \"\n","            f\"Loss: {losses.avg:.4f} \"\n","            )\n","      \n","  return losses.avg\n","\n","def valid_fn(valid_loader, model, loss_function):\n","  start = end = time.time()\n","  losses = AverageMeter()\n","\n","  model.eval()\n","  preds = []\n","\n","  for batch_num, (input_ids, attention_mask, target) in enumerate(valid_loader):\n","    input_ids = input_ids.to(DEVICE)\n","    attention_mask = attention_mask.to(DEVICE)\n","    target = target.to(DEVICE)\n","    batch_size = target.size(0)\n","\n","    # compare loss\n","    with torch.no_grad():\n","      pred = model(input_ids, attention_mask)\n","\n","    loss = loss_function(pred, target)\n","    losses.update(loss.item(), batch_size)\n","\n","    # スコア追加\n","    preds.append(pred.to(\"cpu\").numpy())\n","\n","    if batch_num % 100 == 0 or batch_num == (len(valid_loader) - 1):\n","      print(\n","          f\"EVAL: [{batch_num}/{len(valid_loader)}]\"\n","          f\"Elapsed {timeSince(start, float(batch_num+1) / len(valid_loader)):s}\"\n","          f\"Loss: {losses.avg:.4f}\"\n","      )\n","  predictions = np.concatenate(preds)\n","\n","  return losses.avg, predictions\n","\n","# 予測\n","def inference():\n","    predictions = []\n","\n","    test_dataset = SRWSDataset(test,  inference_only=True)\n","    test_loader = DataLoader(\n","        test_dataset, \n","        batch_size=CONFIG.valid_batch_size, \n","        shuffle=False, \n","        num_workers=4, \n","        pin_memory=True\n","    )\n","\n","    for fold in range(CONFIG.fold):\n","        LOGGER.info(f\"========== model: {CONFIG.model_name} fold: {fold} inference ==========\")\n","        model = SRWSBertModel()\n","        model.to(DEVICE)\n","        model.load_state_dict(torch.load(model_dir +CONFIG.exp + \"/\"+ f\"{CONFIG.model_name.split('/')[1]}_fold{fold}_best.pth\")[\"model\"])\n","        model.eval()\n","        preds = []\n","        for i, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total=len(test_loader)):\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            with torch.no_grad():\n","                y_preds = model(input_ids, attention_mask)\n","            preds.append(y_preds.to(\"cpu\").numpy())\n","        preds = np.concatenate(preds)\n","        predictions.append(preds)\n","    predictions = np.mean(predictions, axis=0)\n","\n","    return predictions"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArvQGSHLZe_G","executionInfo":{"status":"ok","timestamp":1629241876444,"user_tz":-540,"elapsed":15,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["# 最適化（使ってない）\n","# https://signate.jp/competitions/471/discussions/tf-roberta-base-baseline-cv08949-lb08734\n","\n","def opt_fbeta_threshold(y_true, y_pred):\n","  \"\"\"fbeta score計算時のthresholdを最適化\"\"\"\n","  def opt_(x):\n","    return -fbeta_score(y_true, y_pred >= x, beta=7)\n","  result = minimize(opt_, x0=np.array([0.02]), method='Powell')\n","  best_threshold = result['x'].item()\n","  return best_threshold"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHB9WrsPxS96","executionInfo":{"status":"ok","timestamp":1629241876444,"user_tz":-540,"elapsed":15,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["# LOOP\n","def train_loop(train, fold):\n","  LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","  # ====================================================\n","  # Data Loader\n","  # ====================================================\n","  trn_idx = train[train[\"fold\"] != fold].index\n","  val_idx = train[train[\"fold\"] == fold].index\n","\n","  train_folds = train.loc[trn_idx].reset_index(drop=True)\n","  valid_folds = train.loc[val_idx].reset_index(drop=True)\n","\n","  train_dataset = SRWSDataset(train_folds)\n","  valid_dataset = SRWSDataset(valid_folds)\n","\n","  train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CONFIG.train_batch_size,\n","        shuffle=True,\n","        num_workers=4,\n","        pin_memory=True, # https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n","        drop_last=True,\n","  )\n","  valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=CONFIG.valid_batch_size,\n","        shuffle=False,\n","        num_workers=4,\n","        pin_memory=True,\n","        drop_last=False,\n","  )\n","\n","  # ====================================================\n","  # Model\n","  # ====================================================\n","  model = SRWSBertModel()\n","  model.to(DEVICE)\n","\n","  optimizer = AdamW(model.parameters(), lr=CONFIG.lr)\n","\n","  # Loss_function\n","  loss_function = nn.BCELoss()\n","\n","  # ====================================================\n","  # LOOP\n","  # ====================================================\n","\n","  best_score = -1\n","  best_loss = np.inf\n","  best_borders=[]\n","\n","  # 学習\n","  for epoch in range(CONFIG.epochs):\n","    start_time = time.time()\n","\n","    # train\n","    avg_loss = train_fn(model, train_loader, optimizer, epoch, loss_function)\n","\n","    # valid\n","    avg_val_loss, preds = valid_fn(valid_loader, model,loss_function)\n","    valid_labels = valid_folds[\"judgement\"].values\n","\n","    # border最適化\n","    border_m = opt_fbeta_threshold(valid_labels, preds)\n","    best_borders.append(border_m)\n","\n","    # score\n","    score = fbeta_score(valid_labels, np.where(preds < border_m, 0, 1), beta=7.0)\n","\n","    elapsed = time.time() - start_time\n","    LOGGER.info(\n","            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n","    )\n","    LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n","\n","    if score > best_score:\n","      best_score = score\n","      LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} \")\n","      torch.save(\n","                {\"model\": model.state_dict(), \"preds\": preds}, model_dir +CONFIG.exp + \"/\"+ f\"{CONFIG.model_name.split('/')[1]}_fold{fold}_best.pth\"\n","      ) # scibertでの変更\n","  check_point = torch.load(model_dir +CONFIG.exp + \"/\"+ f\"{CONFIG.model_name.split('/')[1]}_fold{fold}_best.pth\")\n","\n","  valid_folds[\"preds\"] = check_point[\"preds\"]\n","\n","  return valid_folds,best_borders"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkzBmBnLBv86","executionInfo":{"status":"ok","timestamp":1629241876444,"user_tz":-540,"elapsed":15,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["def get_result(result_df):\n","    preds = result_df[\"preds\"].values\n","    labels = result_df[\"judgement\"].values\n","    best_threshold = opt_fbeta_threshold(labels, preds)\n","    print(\"Best_Threshold：\" + str(best_threshold))\n","    # 上実行すると、ValueError: Classification metrics can't handle a mix of continuous and binary targets\n","    score = fbeta_score(labels, np.where(preds < best_threshold, 0, 1), beta=7.0)\n","    print(\"Score：\" + str(score))\n","    LOGGER.info(f\"Score: {score:<.5f}\")\n","\n","# inference用に、best_thresholdを出力するようにする関数\n","def get_result_for_cv(result_df,best_border):\n","    preds = result_df[\"preds\"].values\n","    labels = result_df[\"judgement\"].values\n","    #best_threshold = opt_fbeta_threshold(labels, preds)\n","    print(\"Best_Threshold：\" + str(best_border))\n","    # 上実行すると、ValueError: Classification metrics can't handle a mix of continuous and binary targets\n","    score = fbeta_score(labels, np.where(preds < best_border, 0, 1), beta=7.0)\n","    print(\"Score：\" + str(score))\n","    LOGGER.info(f\"Score: {score:<.5f}\")\n","\n","    return score\n","\n","def mean_best_border(*best_borders):\n","    best_border = np.mean(best_borders)\n","    print(\"Best_Threshold：\" + str(best_border))\n","    LOGGER.info(f\"Best_Border: {best_border:<.8f}\")\n","\n","    return best_border"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"9mZGKRQADebR","executionInfo":{"status":"ok","timestamp":1629241876444,"user_tz":-540,"elapsed":15,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["def clean_stopword(text):\n","  stopwords = nltk.corpus.stopwords.words('english')\n","  list_x = text.split()\n","  res = []\n","  for w in list_x:\n","    if w not in stopwords:\n","      res.append(w)\n","  return ' '.join(res)\n","\n","def clean_puncts(x):\n","  # 化学式とかがあるから '-'は削除しないほうがいいか？\n","\n","  puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n","            '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…',\n","            '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─',\n","            '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '«',\n","            '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', '（', '）', '～',\n","            '➡', '％', '⇒', '▶', '「', '➄', '➆',  '➊', '➋', '➌', '➍', '⓪', '①', '②', '③', '④', '⑤', '⑰', '❶', '❷', '❸', '❹', '❺', '❻', '❼', '❽',  \n","            '＝', '※', '㈱', '､', '△', '℮', 'ⅼ', '‐', '｣', '┝', '↳', '◉', '／', '＋', '○',\n","            '【', '】', '✅', '☑', '➤', 'ﾞ', '↳', '〶', '☛', '｢', '⁺', '『', '≫',\n","            'Â©', '<sub>','Aﾎｲ', 'ﾎｲ', \"ﾃｩ\"\n","          ] \n","  # 文字化け対応はここで対応するしかない？\n","  \n","  for punct in puncts:\n","    x = x.replace(punct, '')\n","  return x\n","\n","def _pre_preprocess(x):\n","  return str(x).lower() \n","\n","def rm_num(x, use_num=True):\n","  numbers = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"０\",\"１\",\"２\",\"３\",\"４\",\"５\",\"６\",\"７\",\"８\",\"９\"]\n","  x = re.sub('[0-9]{5,}', '', x)\n","  x = re.sub('[0-9]{4}', '', x)\n","  x = re.sub('[0-9]{3}', '', x)\n","  x = re.sub('[0-9]{2}', '', x)    \n","  for i in numbers:\n","    x = x.replace(str(i), '')        \n","  return x\n","\n","def convert_mojibake(text):\n","  text = text.encode(\"shift-jis\").decode(\"utf-8\", errors=\"ignore\")\n","  return text\n","\n","def remove_double(text):\n","  text = text.replace(\"  \", \" \")\n","  return text\n","\n","def preprocess_text(text):\n","  #text = _pre_preprocess(text)\n","  #text = clean_stopword(text)\n","  text = clean_puncts(text)\n","  text = rm_num(text)\n","  text = remove_double(text)\n","\n","  return text\n","\n","def split_copyright(text):\n","  if \"Copyright\" in text:\n","    text = text.split('Copyright')[0]\n","    return text\n","  else:\n","    return text\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"NeRaL5mh-ozs","executionInfo":{"status":"ok","timestamp":1629241881317,"user_tz":-540,"elapsed":4888,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["pd.set_option(\"display.max_colwidth\", 50)\n","train = pd.read_csv(input_dir + \"train.csv\")\n","test = pd.read_csv(input_dir + \"test.csv\")\n","sub = pd.read_csv(input_dir + \"sample_submit.csv\", header=None)\n","sub.columns = [\"id\", \"judgement\"]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"5pLNyTCB-po5","executionInfo":{"status":"ok","timestamp":1629241881322,"user_tz":-540,"elapsed":22,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"03169458-22b0-477b-baec-0dbcccbc06fa"},"source":["train = get_train_data(train)\n","train.head()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>judgement</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>One-year age changes in MRI brain volumes in o...</td>\n","      <td>Longitudinal studies indicate that declines in...</td>\n","      <td>0</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Supportive CSF biomarker evidence to enhance t...</td>\n","      <td>The present study was undertaken to validate t...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n","      <td>Objective: To report a case series in which ba...</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>New developments in diagnosis and therapy of C...</td>\n","      <td>The etiology and pathogenesis of idiopathic ch...</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                              title  ... judgement  fold\n","0   0  One-year age changes in MRI brain volumes in o...  ...         0     4\n","1   1  Supportive CSF biomarker evidence to enhance t...  ...         0     1\n","2   2  Occurrence of basal ganglia germ cell tumors w...  ...         0     2\n","3   3  New developments in diagnosis and therapy of C...  ...         0     0\n","4   4  Prolonged shedding of SARS-CoV-2 in an elderly...  ...         0     0\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"H36lHBpwcJz3","executionInfo":{"status":"ok","timestamp":1629241881322,"user_tz":-540,"elapsed":17,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"f56a75d4-8db6-4ed5-89e2-12aafaa0a922"},"source":["train[\"title_abst\"] = train[\"title\"] + train[\"abstract\"]\n","train[\"title_abst\"].fillna(train[\"title\"], inplace=True)\n","\n","test[\"title_abst\"] = test[\"title\"] + test[\"abstract\"]\n","test[\"title_abst\"].fillna(test[\"title\"], inplace=True)\n","\n","train.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>judgement</th>\n","      <th>fold</th>\n","      <th>title_abst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>One-year age changes in MRI brain volumes in o...</td>\n","      <td>Longitudinal studies indicate that declines in...</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>One-year age changes in MRI brain volumes in o...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Supportive CSF biomarker evidence to enhance t...</td>\n","      <td>The present study was undertaken to validate t...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Supportive CSF biomarker evidence to enhance t...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n","      <td>Objective: To report a case series in which ba...</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>New developments in diagnosis and therapy of C...</td>\n","      <td>The etiology and pathogenesis of idiopathic ch...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>New developments in diagnosis and therapy of C...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                         title_abst\n","0   0  ...  One-year age changes in MRI brain volumes in o...\n","1   1  ...  Supportive CSF biomarker evidence to enhance t...\n","2   2  ...  Occurrence of basal ganglia germ cell tumors w...\n","3   3  ...  New developments in diagnosis and therapy of C...\n","4   4  ...  Prolonged shedding of SARS-CoV-2 in an elderly...\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"kkKHrVztDPUW","executionInfo":{"status":"ok","timestamp":1629241894904,"user_tz":-540,"elapsed":13598,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}}},"source":["# preprocess\n","train[\"title_abst\"] = train[\"title_abst\"].apply(lambda x: preprocess_text(x))\n","test[\"title_abst\"] = test[\"title_abst\"].apply(lambda x: preprocess_text(x))\n","\n","# titleの単語数が3以下のものは除外してみる\n","train[\"title_word_len\"] = train[\"title\"].str.split(\" \").str.len()\n","train = train[train[\"title_word_len\"]>3]\n","\n","# titleが他言語の場合は除外\n","train[\"title_lang\"] = train[\"title\"].fillna(\"\").map(lambda x: cld2.detect(x)[2][0][1])\n","train = train[(train[\"title_lang\"]==\"en\")|(train[\"title_lang\"]==\"un\")]\n","\n","# copyright以降は削除したい\n","train[\"title_abst\"] = train[\"title_abst\"].apply(lambda x: split_copyright(x))\n","test[\"title_abst\"] = test[\"title_abst\"].apply(lambda x: split_copyright(x))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0lY2xUY7vBst","executionInfo":{"status":"ok","timestamp":1629241895335,"user_tz":-540,"elapsed":453,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"8f796cd9-3bf1-474b-ed29-f238981e232f"},"source":["print(len(pd.read_csv(input_dir + \"train.csv\")))\n","print(len(train))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["27145\n","26921\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2f36214382834a1588cdfa5584560e45","e5e4b40deea54c208979380bef5a9239","0b032a29679441b59694fb6f57916140","39b5dd4482b046eab919475046546178","2a14e629293c4ab4a290a47fae5d9ae9","67ae6613a8894106bde55bbd4c1e19a6","beb2457c5ecb421eafa8c4a6e854e716","06c000efc5834fa29f537992bcb1572f","13d7fa0921c7465eab624d5cf0d0d881","97a3c191e7a840f6a495709fe0bb0b76","474279bb58fe4f30afdb7aebd4ae8b39","3d2078a8053c4def8d3d1b1d7ec6c8b9","25b8d14f096a42faaad75c0eeb5a9850","041d817fd54b4807b3a393b6ed514f62","23b9344e14194ce38ac2907aa45e856f","d2eb195d22f9427688713d01518242ce","a1867ca9e60543a2bfce2002a9106923","79f3977111e745ae9e853e862345cdc9","c913241dce8d4594b169f7619b18858f","75c844118ec741c99d7c6d7d647f443e","b5d9417fb06642fc82b4df43c0050ea0","594c7595285d4bfeab63ad4db21e0af2","5e0e776ce6b14813b78d5be5ec4767ec","6bf5b7560b584b8ca8251f48606e92c6","a7fa7cee9d5a4892bc89df6f0557f327","ded97e23635746db8cc43a4633289774","51da5525d4434dc0ba63f70223a2a8ed","2711dd85706e484c9faf9f94ffdf2c47","74c6e9beed824f80ade9f88b0ca98366","fef611aa515e4908bf9b58a25daae964","932fadd1a9b649f9bc306b390a373496","b2353821e5d04be994023c01ed6c2a9f","2876de029b7440ff926f0a3cac2f11c0"]},"id":"n8wvJSraCIIi","executionInfo":{"status":"ok","timestamp":1629244531856,"user_tz":-540,"elapsed":2636525,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"34af487b-ff3d-4b16-d298-d9a190e58a58"},"source":["# Training\n","#border = len(train[train[\"judgement\"] == 1]) / len(train[\"judgement\"]) # 0.023245467689912133\n","#border = border * 0.6\n","\n","mean_border_folds = []\n"," \n","oof_df = pd.DataFrame()\n","for fold in range(CONFIG.fold):\n","  _oof_df,best_borders = train_loop(train, fold)\n","  oof_df = pd.concat([oof_df, _oof_df])\n","  LOGGER.info(f\"========== fold: {fold} result ==========\")\n","  best_border_fold = mean_best_border(best_borders)\n","  mean_border_folds.append(best_border_fold)\n","        \n","# CV result\n","LOGGER.info(f\"========== CV ==========\")\n","best_border = mean_best_border(mean_border_folds)\n","get_result_for_cv(oof_df,best_border)\n","    \n","# Save OOF result\n","oof_df.to_csv(pred_dir +CONFIG.exp + \"/oof_df.csv\", index=False)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["========== fold: 0 training ==========\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f36214382834a1588cdfa5584560e45","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3d2078a8053c4def8d3d1b1d7ec6c8b9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/313 [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e0e776ce6b14813b78d5be5ec4767ec","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/441M [00:00<?, ?B/s]"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: [1][0/1345] Elapsed 0m 0s (remain 14m 51s) Loss: 0.6317 \n","Epoch: [1][100/1345] Elapsed 0m 26s (remain 5m 21s) Loss: 0.1677 \n","Epoch: [1][200/1345] Elapsed 0m 51s (remain 4m 54s) Loss: 0.1275 \n","Epoch: [1][300/1345] Elapsed 1m 17s (remain 4m 28s) Loss: 0.1096 \n","Epoch: [1][400/1345] Elapsed 1m 42s (remain 4m 2s) Loss: 0.1008 \n","Epoch: [1][500/1345] Elapsed 2m 8s (remain 3m 36s) Loss: 0.0968 \n","Epoch: [1][600/1345] Elapsed 2m 34s (remain 3m 10s) Loss: 0.0938 \n","Epoch: [1][700/1345] Elapsed 2m 59s (remain 2m 45s) Loss: 0.0873 \n","Epoch: [1][800/1345] Elapsed 3m 25s (remain 2m 19s) Loss: 0.0840 \n","Epoch: [1][900/1345] Elapsed 3m 51s (remain 1m 53s) Loss: 0.0794 \n","Epoch: [1][1000/1345] Elapsed 4m 16s (remain 1m 28s) Loss: 0.0785 \n","Epoch: [1][1100/1345] Elapsed 4m 42s (remain 1m 2s) Loss: 0.0785 \n","Epoch: [1][1200/1345] Elapsed 5m 8s (remain 0m 36s) Loss: 0.0779 \n","Epoch: [1][1300/1345] Elapsed 5m 34s (remain 0m 11s) Loss: 0.0764 \n","Epoch: [1][1344/1345] Elapsed 5m 45s (remain 0m 0s) Loss: 0.0755 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 55s)Loss: 0.0148\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 11s)Loss: 0.0503\n","EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0496\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0755  avg_val_loss: 0.0496  time: 373s\n","Epoch 1 - Score: 0.8939393939393939\n","Epoch 1 - Save Best Score: 0.8939 \n","========== fold: 0 result ==========\n","Best_Border: 0.01561956\n","========== fold: 1 training ==========\n"],"name":"stderr"},{"output_type":"stream","text":["Best_Threshold：0.015619561455741586\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: [1][0/1346] Elapsed 0m 0s (remain 10m 7s) Loss: 0.8051 \n","Epoch: [1][100/1346] Elapsed 0m 25s (remain 5m 19s) Loss: 0.1472 \n","Epoch: [1][200/1346] Elapsed 0m 51s (remain 4m 53s) Loss: 0.1237 \n","Epoch: [1][300/1346] Elapsed 1m 17s (remain 4m 27s) Loss: 0.1168 \n","Epoch: [1][400/1346] Elapsed 1m 42s (remain 4m 2s) Loss: 0.1067 \n","Epoch: [1][500/1346] Elapsed 2m 8s (remain 3m 36s) Loss: 0.1007 \n","Epoch: [1][600/1346] Elapsed 2m 34s (remain 3m 11s) Loss: 0.0950 \n","Epoch: [1][700/1346] Elapsed 3m 0s (remain 2m 45s) Loss: 0.0929 \n","Epoch: [1][800/1346] Elapsed 3m 25s (remain 2m 19s) Loss: 0.0878 \n","Epoch: [1][900/1346] Elapsed 3m 51s (remain 1m 54s) Loss: 0.0861 \n","Epoch: [1][1000/1346] Elapsed 4m 17s (remain 1m 28s) Loss: 0.0876 \n","Epoch: [1][1100/1346] Elapsed 4m 43s (remain 1m 2s) Loss: 0.0861 \n","Epoch: [1][1200/1346] Elapsed 5m 8s (remain 0m 37s) Loss: 0.0830 \n","Epoch: [1][1300/1346] Elapsed 5m 34s (remain 0m 11s) Loss: 0.0807 \n","Epoch: [1][1345/1346] Elapsed 5m 46s (remain 0m 0s) Loss: 0.0795 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 53s)Loss: 0.0119\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 11s)Loss: 0.0431\n","EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0464\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0795  avg_val_loss: 0.0464  time: 374s\n","Epoch 1 - Score: 0.887830229536596\n","Epoch 1 - Save Best Score: 0.8878 \n","========== fold: 1 result ==========\n","Best_Border: 0.00628419\n","========== fold: 2 training ==========\n"],"name":"stderr"},{"output_type":"stream","text":["Best_Threshold：0.006284194063221026\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: [1][0/1345] Elapsed 0m 0s (remain 9m 44s) Loss: 0.6483 \n","Epoch: [1][100/1345] Elapsed 0m 25s (remain 5m 19s) Loss: 0.1579 \n","Epoch: [1][200/1345] Elapsed 0m 51s (remain 4m 52s) Loss: 0.1423 \n","Epoch: [1][300/1345] Elapsed 1m 17s (remain 4m 27s) Loss: 0.1221 \n","Epoch: [1][400/1345] Elapsed 1m 42s (remain 4m 1s) Loss: 0.1120 \n","Epoch: [1][500/1345] Elapsed 2m 8s (remain 3m 35s) Loss: 0.1023 \n","Epoch: [1][600/1345] Elapsed 2m 33s (remain 3m 10s) Loss: 0.0993 \n","Epoch: [1][700/1345] Elapsed 2m 59s (remain 2m 44s) Loss: 0.0945 \n","Epoch: [1][800/1345] Elapsed 3m 25s (remain 2m 19s) Loss: 0.0902 \n","Epoch: [1][900/1345] Elapsed 3m 50s (remain 1m 53s) Loss: 0.0864 \n","Epoch: [1][1000/1345] Elapsed 4m 16s (remain 1m 28s) Loss: 0.0836 \n","Epoch: [1][1100/1345] Elapsed 4m 41s (remain 1m 2s) Loss: 0.0810 \n","Epoch: [1][1200/1345] Elapsed 5m 7s (remain 0m 36s) Loss: 0.0790 \n","Epoch: [1][1300/1345] Elapsed 5m 33s (remain 0m 11s) Loss: 0.0773 \n","Epoch: [1][1344/1345] Elapsed 5m 44s (remain 0m 0s) Loss: 0.0765 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 53s)Loss: 0.0151\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 10s)Loss: 0.0534\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0765  avg_val_loss: 0.0598  time: 372s\n","Epoch 1 - Score: 0.8234614273331408\n","Epoch 1 - Save Best Score: 0.8235 \n"],"name":"stderr"},{"output_type":"stream","text":["EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0598\n"],"name":"stdout"},{"output_type":"stream","text":["========== fold: 2 result ==========\n","Best_Border: 0.02438822\n","========== fold: 3 training ==========\n"],"name":"stderr"},{"output_type":"stream","text":["Best_Threshold：0.024388217887538435\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: [1][0/1345] Elapsed 0m 0s (remain 9m 45s) Loss: 0.5612 \n","Epoch: [1][100/1345] Elapsed 0m 25s (remain 5m 19s) Loss: 0.1727 \n","Epoch: [1][200/1345] Elapsed 0m 51s (remain 4m 52s) Loss: 0.1291 \n","Epoch: [1][300/1345] Elapsed 1m 17s (remain 4m 27s) Loss: 0.1209 \n","Epoch: [1][400/1345] Elapsed 1m 42s (remain 4m 2s) Loss: 0.1179 \n","Epoch: [1][500/1345] Elapsed 2m 8s (remain 3m 36s) Loss: 0.1125 \n","Epoch: [1][600/1345] Elapsed 2m 34s (remain 3m 10s) Loss: 0.1053 \n","Epoch: [1][700/1345] Elapsed 2m 59s (remain 2m 44s) Loss: 0.1028 \n","Epoch: [1][800/1345] Elapsed 3m 25s (remain 2m 19s) Loss: 0.0998 \n","Epoch: [1][900/1345] Elapsed 3m 50s (remain 1m 53s) Loss: 0.0970 \n","Epoch: [1][1000/1345] Elapsed 4m 16s (remain 1m 28s) Loss: 0.0960 \n","Epoch: [1][1100/1345] Elapsed 4m 41s (remain 1m 2s) Loss: 0.0946 \n","Epoch: [1][1200/1345] Elapsed 5m 7s (remain 0m 36s) Loss: 0.0926 \n","Epoch: [1][1300/1345] Elapsed 5m 33s (remain 0m 11s) Loss: 0.0897 \n","Epoch: [1][1344/1345] Elapsed 5m 44s (remain 0m 0s) Loss: 0.0889 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 55s)Loss: 0.0588\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 10s)Loss: 0.0507\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0889  avg_val_loss: 0.0552  time: 372s\n","Epoch 1 - Score: 0.8654545454545455\n","Epoch 1 - Save Best Score: 0.8655 \n"],"name":"stderr"},{"output_type":"stream","text":["EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0552\n"],"name":"stdout"},{"output_type":"stream","text":["========== fold: 3 result ==========\n","Best_Border: 0.02194582\n","========== fold: 4 training ==========\n"],"name":"stderr"},{"output_type":"stream","text":["Best_Threshold：0.02194581585759745\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_mimic_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: [1][0/1346] Elapsed 0m 0s (remain 10m 13s) Loss: 0.6787 \n","Epoch: [1][100/1346] Elapsed 0m 25s (remain 5m 20s) Loss: 0.1558 \n","Epoch: [1][200/1346] Elapsed 0m 51s (remain 4m 54s) Loss: 0.1353 \n","Epoch: [1][300/1346] Elapsed 1m 17s (remain 4m 28s) Loss: 0.1258 \n","Epoch: [1][400/1346] Elapsed 1m 43s (remain 4m 2s) Loss: 0.1159 \n","Epoch: [1][500/1346] Elapsed 2m 8s (remain 3m 37s) Loss: 0.1117 \n","Epoch: [1][600/1346] Elapsed 2m 34s (remain 3m 11s) Loss: 0.1054 \n","Epoch: [1][700/1346] Elapsed 3m 0s (remain 2m 45s) Loss: 0.1011 \n","Epoch: [1][800/1346] Elapsed 3m 26s (remain 2m 20s) Loss: 0.0961 \n","Epoch: [1][900/1346] Elapsed 3m 51s (remain 1m 54s) Loss: 0.0904 \n","Epoch: [1][1000/1346] Elapsed 4m 17s (remain 1m 28s) Loss: 0.0872 \n","Epoch: [1][1100/1346] Elapsed 4m 43s (remain 1m 3s) Loss: 0.0844 \n","Epoch: [1][1200/1346] Elapsed 5m 9s (remain 0m 37s) Loss: 0.0817 \n","Epoch: [1][1300/1346] Elapsed 5m 35s (remain 0m 11s) Loss: 0.0790 \n","Epoch: [1][1345/1346] Elapsed 5m 46s (remain 0m 0s) Loss: 0.0778 \n","EVAL: [0/168]Elapsed 0m 0s (remain 0m 56s)Loss: 0.0083\n","EVAL: [100/168]Elapsed 0m 16s (remain 0m 10s)Loss: 0.0498\n","EVAL: [167/168]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0484\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0778  avg_val_loss: 0.0484  time: 374s\n","Epoch 1 - Score: 0.8793025702690517\n","Epoch 1 - Save Best Score: 0.8793 \n","========== fold: 4 result ==========\n","Best_Border: 0.01602684\n","========== CV ==========\n","Best_Border: 0.01685293\n","Score: 0.86021\n"],"name":"stderr"},{"output_type":"stream","text":["Best_Threshold：0.016026842123400466\n","Best_Threshold：0.016852926277499795\n","Best_Threshold：0.016852926277499795\n","Score：0.8602118806622008\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsmKzZM8fhSc","executionInfo":{"status":"ok","timestamp":1629211353963,"user_tz":-540,"elapsed":322,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"38b97291-fa8f-4e9c-d3b8-48dd59bdf212"},"source":["best_border"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.026602333932376643"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vn-D60_1CVgv","executionInfo":{"status":"ok","timestamp":1629212666304,"user_tz":-540,"elapsed":1301985,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"}},"outputId":"84233c63-de49-4593-e4ec-70ba7de8b059"},"source":["# inference, submit\n","# border を出力できるようにしたい\n","#best_border = 0.03955983\n","predictions = inference()\n","predictions = np.where(predictions < best_border, 0, 1)\n","\n","# submission\n","sub[\"judgement\"] = predictions\n","sub.to_csv(submission_dir +CONFIG.exp+ \"_submission.csv\", index=False, header=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["========== model: bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 fold: 0 inference ==========\n","Some weights of the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:31<00:00,  6.05it/s]\n","========== model: bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 fold: 1 inference ==========\n","Some weights of the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:30<00:00,  6.06it/s]\n","========== model: bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 fold: 2 inference ==========\n","Some weights of the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:30<00:00,  6.07it/s]\n","========== model: bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 fold: 3 inference ==========\n","Some weights of the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:30<00:00,  6.07it/s]\n","========== model: bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 fold: 4 inference ==========\n","Some weights of the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12 and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:30<00:00,  6.08it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"SNKnI9WhPGCb"},"source":[" "],"execution_count":null,"outputs":[]}]}