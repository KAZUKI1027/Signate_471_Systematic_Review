{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Exp010.ipynb","provenance":[{"file_id":"14buLHzwACALiMi8dqkgFhlo3DFBtP2eS","timestamp":1629043489149}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bd3893e53a7749d880f64c176eb23611":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f62e21bc6b44c3c983d254a8ebaa92d","IPY_MODEL_072111c03c1c4882a3f499f9be2c17ed","IPY_MODEL_e9924a4393e64c0eb8f5e03768f680e5"],"layout":"IPY_MODEL_ff7a72323a5b4c73ad4e4380b1ef38d9"}},"5f62e21bc6b44c3c983d254a8ebaa92d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_903cbf5d65e5457a9c7374aa72bf694b","placeholder":"​","style":"IPY_MODEL_dec83bce8306464d9bde019c260d9f88","value":"Downloading: 100%"}},"072111c03c1c4882a3f499f9be2c17ed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6019c8841014ac9ab5209aa8928c707","max":225062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17132604c6f24c9c8abdf065c670cde3","value":225062}},"e9924a4393e64c0eb8f5e03768f680e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f195b06d559c48f7abe292e484868a8c","placeholder":"​","style":"IPY_MODEL_315f45cde21a46ca91617696bf1b083f","value":" 225k/225k [00:00&lt;00:00, 688kB/s]"}},"ff7a72323a5b4c73ad4e4380b1ef38d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"903cbf5d65e5457a9c7374aa72bf694b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dec83bce8306464d9bde019c260d9f88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6019c8841014ac9ab5209aa8928c707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17132604c6f24c9c8abdf065c670cde3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f195b06d559c48f7abe292e484868a8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"315f45cde21a46ca91617696bf1b083f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"823fe6be14b9436ebb46761f6962144d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73b6cee40e194042ad12e11abb68c20c","IPY_MODEL_ac62dafe1ef34bf8b493a99d82313334","IPY_MODEL_e37a56082ae84e3a8b8327b9d1f66748"],"layout":"IPY_MODEL_f9f7747188b6401da4245032fb26ea3a"}},"73b6cee40e194042ad12e11abb68c20c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56c2d2892f1246a080a29b5767624563","placeholder":"​","style":"IPY_MODEL_cc588f7fe9654eafb134176e9212aa62","value":"Downloading: 100%"}},"ac62dafe1ef34bf8b493a99d82313334":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a41ea72a0b49478d9aff0e8e828184d3","max":462,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4db8c1893c104271a15011cfcc499041","value":462}},"e37a56082ae84e3a8b8327b9d1f66748":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1001c7a955f43d6bfe63e4f40ff7e5a","placeholder":"​","style":"IPY_MODEL_3df8f318e62049beb44439f7c5625679","value":" 462/462 [00:00&lt;00:00, 18.9kB/s]"}},"f9f7747188b6401da4245032fb26ea3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56c2d2892f1246a080a29b5767624563":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc588f7fe9654eafb134176e9212aa62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a41ea72a0b49478d9aff0e8e828184d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4db8c1893c104271a15011cfcc499041":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b1001c7a955f43d6bfe63e4f40ff7e5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3df8f318e62049beb44439f7c5625679":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aeb18fb851c94f16b983164d35e12196":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_451cc38684fb483ebd7b7123c68694d1","IPY_MODEL_a051dfdfbfaa412099faa82589fa0fec","IPY_MODEL_85c2bece609446bc96806a4d6aaa6c13"],"layout":"IPY_MODEL_fd8bc4c0e22b4c1aa6cbb196553a5d88"}},"451cc38684fb483ebd7b7123c68694d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bc08788f4154bbbbf72e191a1da0484","placeholder":"​","style":"IPY_MODEL_60f3ab5bdbea4963ab6f8fb033bb6790","value":"Downloading: 100%"}},"a051dfdfbfaa412099faa82589fa0fec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a279d13943d74a0a88119106d7dcec65","max":438012727,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86430e65883841b7b8e38ab4d1d5d4a4","value":438012727}},"85c2bece609446bc96806a4d6aaa6c13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2444f387b79041e4ad12399920fb8ce9","placeholder":"​","style":"IPY_MODEL_c78448b500114d8483c25d30a0cee4d3","value":" 438M/438M [00:07&lt;00:00, 57.7MB/s]"}},"fd8bc4c0e22b4c1aa6cbb196553a5d88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bc08788f4154bbbbf72e191a1da0484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60f3ab5bdbea4963ab6f8fb033bb6790":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a279d13943d74a0a88119106d7dcec65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86430e65883841b7b8e38ab4d1d5d4a4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2444f387b79041e4ad12399920fb8ce9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c78448b500114d8483c25d30a0cee4d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"JXepDb7__Oml"},"source":["## Exp-010 (ULMS BERT)\n","\n","Exp-009からの変更点\n","- Revise_train_data_judgement2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sa2hpabgm7vJ","executionInfo":{"elapsed":57106,"status":"ok","timestamp":1630507828041,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"},"user_tz":-540},"outputId":"34b35c25-a52e-416a-ecd9-8869409efdfe"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKlEabxO_MSm","executionInfo":{"elapsed":14,"status":"ok","timestamp":1630507828042,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"},"user_tz":-540},"outputId":"7387223f-5e5b-4a99-c117-5a80b5a008ed"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Wed Sep  1 14:50:27 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vE7GdrrE_dev","executionInfo":{"elapsed":26923,"status":"ok","timestamp":1630507854957,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"},"user_tz":-540},"outputId":"6771b62f-84ae-41c6-b8b6-f95771377c81"},"source":["!pip install transformers pycld2"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 14.5 MB/s \n","\u001b[?25hCollecting pycld2\n","  Downloading pycld2-0.41.tar.gz (41.4 MB)\n","\u001b[K     |████████████████████████████████| 41.4 MB 66 kB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 64.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 86.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 6.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 60.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Building wheels for collected packages: pycld2\n","  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834232 sha256=9528639fc1f0d52a9289820f8fceb5715554f02bb0adf2991f60b980f93b470b\n","  Stored in directory: /root/.cache/pip/wheels/ed/e4/58/ed2e9f43c07d617cc81fe7aff0fc6e42b16c9cf6afe960b614\n","Successfully built pycld2\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers, pycld2\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.16 pycld2-0.41 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n"]}]},{"cell_type":"code","metadata":{"id":"O3gDMmLR_oJ3"},"source":["input_dir = \"/content/drive/MyDrive/07_Competition/signate-471/data/\"\n","output_dir = \"/content/drive/MyDrive/07_Competition/signate-471/log/\"\n","submission_dir = \"/content/drive/MyDrive/07_Competition/signate-471/submission/\"\n","model_dir = \"/content/drive/MyDrive/07_Competition/signate-471/model_bin/\"\n","pred_dir = \"/content/drive/MyDrive/07_Competition/signate-471/pred/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88KVneP6_o1Z","executionInfo":{"elapsed":7490,"status":"ok","timestamp":1630507862442,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"},"user_tz":-540},"outputId":"ee188e0b-ad0c-4cd3-e75b-4366fdb3b17a"},"source":["import os\n","import math\n","import random\n","import pandas as pd\n","import numpy as np\n","from glob import glob\n","import gc\n","gc.enable()\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.optim as optim\n","from torch.optim.optimizer import Optimizer\n","import torch.optim.lr_scheduler as lr_scheduler\n","from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n","\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import fbeta_score\n","\n","from transformers import BertConfig, RobertaConfig\n","from transformers import (get_cosine_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup)\n","from transformers import BertTokenizer, RobertaTokenizer\n","from transformers import BertModel, RobertaModel\n","from transformers import AutoConfig, BertConfig, RobertaConfig\n","from transformers import BertForSequenceClassification, RobertaForSequenceClassification\n","from torch import cuda\n","import time\n","\n","from transformers import AdamW\n","from transformers import AutoTokenizer\n","from transformers import AutoModel, AutoModelForSequenceClassification\n","from transformers import MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING\n","from transformers import get_linear_schedule_with_warmup\n","\n","from IPython.display import clear_output\n","from tqdm import tqdm, trange\n","\n","import re\n","import nltk\n","import spacy\n","from nltk.corpus import stopwords\n","import pycld2 as cld2\n","from scipy.optimize import minimize, minimize_scalar\n","import regex\n","nltk.download('stopwords')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"slgK2kwa_tdt"},"source":["class CFG:\n","  exp = \"exp10h\"\n","  seed = 71\n","  fold = 5\n","  max_len = 280\n","  epochs = 1\n","  lr = 2e-5\n","  train_batch_size = 16\n","  valid_batch_size = 32\n","  model_name = \"GanjinZero/UMLSBert_ENG\"\n","\n","CONFIG = CFG()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWMPal_oAmmz"},"source":["os.makedirs(model_dir+CONFIG.exp+\"/\", exist_ok=True)\n","os.makedirs(pred_dir+CONFIG.exp+\"/\", exist_ok=True)\n","os.makedirs(output_dir+CONFIG.exp+\"/\", exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_d2AXNBAkKu"},"source":["def set_random_seed(random_seed):\n","    random.seed(random_seed)\n","    np.random.seed(random_seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n","\n","    torch.manual_seed(random_seed)\n","    torch.cuda.manual_seed(random_seed)\n","    torch.cuda.manual_seed_all(random_seed)\n","\n","    torch.backends.cudnn.deterministic = True\n","\n","set_random_seed(CONFIG.seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n47LBGkly0mL"},"source":["DEVICE = torch.device('cuda') if cuda.is_available() else 'cpu'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"em7TEBclApr_"},"source":["def init_logger(log_file=output_dir + CONFIG.exp+ f\"/{CONFIG.exp}_train.log\"):\n","    from logging import INFO, FileHandler, Formatter, StreamHandler, getLogger\n","\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=log_file)\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = init_logger()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WOh95cXMAxta"},"source":["def get_train_data(train):\n","    # 交差検証 用の番号を振ります。\n","    Fold = StratifiedKFold(n_splits=CONFIG.fold, shuffle=True, random_state=CONFIG.seed)\n","    for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"judgement\"])):\n","        train.loc[val_index, \"fold\"] = int(n)\n","    train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n","\n","    return train\n","\n","def get_test_data(test):\n","    return test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5V4URD_dAY2t"},"source":["class SRWSDataset(Dataset):\n","  def __init__(self, df, inference_only=False):\n","\n","    # Berttokenizer\n","    tokenizer = BertTokenizer.from_pretrained(CONFIG.model_name)\n","\n","    self.df = df\n","    self.inference_only = inference_only # \"train\":False or \"test\":True\n","    self.text = self.df[\"title_abst\"].tolist() # text\n","\n","    if not self.inference_only:\n","      # ここvalueだけ\n","      self.target = df[\"judgement\"].values\n","      \n","    self.encoded = tokenizer.batch_encode_plus(\n","        self.text,\n","        padding = \"max_length\",\n","        max_length = CONFIG.max_len,\n","        truncation = True,\n","        return_attention_mask=True\n","    )\n","\n","  def __len__(self):\n","    return len(self.df)\n","\n","  def __getitem__(self, index):\n","    input_ids = torch.tensor(self.encoded[\"input_ids\"][index])\n","    attention_mask = torch.tensor(self.encoded[\"attention_mask\"][index])\n","\n","    # returnをsetかdictで返すかは自由\n","    if self.inference_only:\n","      return (input_ids, attention_mask)\n","\n","    else:\n","      # ここで、tensor に変更している\n","      target = torch.tensor(self.target[index]).float()\n","      return (input_ids, attention_mask, target)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EdX0AIdEAw7"},"source":["class SRWSBertModel(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","    # config を設定することで、元の設定を変更できる？\n","    # https://www.kaggle.com/c/commonlitreadabilityprize/discussion/260729\n","    # 最終的にsigmoidに通すから、num_labelsは1でいい\n","    self.bert = BertForSequenceClassification.from_pretrained(CONFIG.model_name, num_labels=1)\n","    # この辺を調整することで、モデル内の最終層に追加することができる。\n","    # bertのoutputがclassificationなんで、そこを変更しないと\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, input_ids, attention_mask):\n","    bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask) \n","    bert_output = self.sigmoid(bert_output.logits).squeeze()\n","\n","    return bert_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hB8VYTNW1MJc"},"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return \"%dm %ds\" % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b76ASi80wKMA"},"source":["# 学習\n","def train_fn(model, train_loader, optimizer, epoch, loss_function, scheduler=None):\n","  start = end = time.time()\n","  losses = AverageMeter()\n","  model.train()\n","\n","  for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","\n","    input_ids = input_ids.to(DEVICE)\n","    attention_mask = attention_mask.to(DEVICE)\n","    target = target.to(DEVICE)\n","    batch_size = target.size(0)\n","\n","    pred = model(input_ids, attention_mask)\n","\n","    # Loss算出\n","    loss = loss_function(pred, target)\n","    losses.update(loss.item(), batch_size)\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if scheduler:\n","      scheduler.step()\n","\n","    if batch_num % 100 == 0 or batch_num == (len(train_loader) -1):\n","      print(\n","            f\"Epoch: [{epoch + 1}][{batch_num}/{len(train_loader)}] \"\n","            f\"Elapsed {timeSince(start, float(batch_num + 1) / len(train_loader)):s} \"\n","            f\"Loss: {losses.avg:.4f} \"\n","            )\n","      \n","  return losses.avg\n","\n","def valid_fn(valid_loader, model, loss_function):\n","  start = end = time.time()\n","  losses = AverageMeter()\n","\n","  model.eval()\n","  preds = []\n","\n","  for batch_num, (input_ids, attention_mask, target) in enumerate(valid_loader):\n","    input_ids = input_ids.to(DEVICE)\n","    attention_mask = attention_mask.to(DEVICE)\n","    target = target.to(DEVICE)\n","    batch_size = target.size(0)\n","\n","    # compare loss\n","    with torch.no_grad():\n","      pred = model(input_ids, attention_mask)\n","\n","    loss = loss_function(pred, target)\n","    losses.update(loss.item(), batch_size)\n","\n","    # スコア追加\n","    preds.append(pred.to(\"cpu\").numpy())\n","\n","    if batch_num % 100 == 0 or batch_num == (len(valid_loader) - 1):\n","      print(\n","          f\"EVAL: [{batch_num}/{len(valid_loader)}]\"\n","          f\"Elapsed {timeSince(start, float(batch_num+1) / len(valid_loader)):s}\"\n","          f\"Loss: {losses.avg:.4f}\"\n","      )\n","  predictions = np.concatenate(preds)\n","\n","  return losses.avg, predictions\n","\n","# 予測\n","def inference():\n","    predictions = []\n","\n","    test_dataset = SRWSDataset(test,  inference_only=True)\n","    test_loader = DataLoader(\n","        test_dataset, \n","        batch_size=CONFIG.valid_batch_size, \n","        shuffle=False, \n","        num_workers=4, \n","        pin_memory=True\n","    )\n","\n","    for fold in range(CONFIG.fold):\n","        LOGGER.info(f\"========== model: {CONFIG.model_name} fold: {fold} inference ==========\")\n","        model = SRWSBertModel()\n","        model.to(DEVICE)\n","        model.load_state_dict(torch.load(model_dir +CONFIG.exp + \"/\"+ f\"{CONFIG.model_name.split('/')[1]}_fold{fold}_best.pth\")[\"model\"])\n","        model.eval()\n","        preds = []\n","        for i, (input_ids, attention_mask) in tqdm(enumerate(test_loader), total=len(test_loader)):\n","            input_ids = input_ids.to(DEVICE)\n","            attention_mask = attention_mask.to(DEVICE)\n","            with torch.no_grad():\n","                y_preds = model(input_ids, attention_mask)\n","            preds.append(y_preds.to(\"cpu\").numpy())\n","        preds = np.concatenate(preds)\n","        predictions.append(preds)\n","    predictions = np.mean(predictions, axis=0)\n","\n","    return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ArvQGSHLZe_G"},"source":["# 最適化（使ってない）\n","# https://signate.jp/competitions/471/discussions/tf-roberta-base-baseline-cv08949-lb08734\n","\n","def opt_fbeta_threshold(y_true, y_pred):\n","  \"\"\"fbeta score計算時のthresholdを最適化\"\"\"\n","  def opt_(x):\n","    return -fbeta_score(y_true, y_pred >= x, beta=7)\n","  result = minimize(opt_, x0=np.array([0.02]), method='Powell')\n","  best_threshold = result['x'].item()\n","  return best_threshold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHB9WrsPxS96"},"source":["# LOOP\n","def train_loop(train, fold):\n","  LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","  # ====================================================\n","  # Data Loader\n","  # ====================================================\n","  trn_idx = train[train[\"fold\"] != fold].index\n","  val_idx = train[train[\"fold\"] == fold].index\n","\n","  train_folds = train.loc[trn_idx].reset_index(drop=True)\n","  valid_folds = train.loc[val_idx].reset_index(drop=True)\n","\n","  train_dataset = SRWSDataset(train_folds)\n","  valid_dataset = SRWSDataset(valid_folds)\n","\n","  train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=CONFIG.train_batch_size,\n","        shuffle=True,\n","        num_workers=4,\n","        pin_memory=True, # https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n","        drop_last=True,\n","  )\n","  valid_loader = DataLoader(\n","        valid_dataset,\n","        batch_size=CONFIG.valid_batch_size,\n","        shuffle=False,\n","        num_workers=4,\n","        pin_memory=True,\n","        drop_last=False,\n","  )\n","\n","  # ====================================================\n","  # Model\n","  # ====================================================\n","  model = SRWSBertModel()\n","  model.to(DEVICE)\n","\n","  optimizer = AdamW(model.parameters(), lr=CONFIG.lr)\n","\n","  # Loss_function\n","  loss_function = nn.BCELoss()\n","\n","  # ====================================================\n","  # LOOP\n","  # ====================================================\n","\n","  best_score = -1\n","  best_loss = np.inf\n","  best_borders=[]\n","\n","  # 学習\n","  for epoch in range(CONFIG.epochs):\n","    start_time = time.time()\n","\n","    # train\n","    avg_loss = train_fn(model, train_loader, optimizer, epoch, loss_function)\n","\n","    # valid\n","    avg_val_loss, preds = valid_fn(valid_loader, model,loss_function)\n","    valid_labels = valid_folds[\"judgement\"].values\n","\n","    # border最適化\n","    border_m = opt_fbeta_threshold(valid_labels, preds)\n","    best_borders.append(border_m)\n","\n","    # score\n","    score = fbeta_score(valid_labels, np.where(preds < border_m, 0, 1), beta=7.0)\n","\n","    elapsed = time.time() - start_time\n","    LOGGER.info(\n","            f\"Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s\"\n","    )\n","    LOGGER.info(f\"Epoch {epoch+1} - Score: {score}\")\n","\n","    if score > best_score:\n","      best_score = score\n","      LOGGER.info(f\"Epoch {epoch+1} - Save Best Score: {best_score:.4f} \")\n","      torch.save(\n","                {\"model\": model.state_dict(), \"preds\": preds}, model_dir +CONFIG.exp + \"/\"+ f\"{CONFIG.model_name.split('/')[1]}_fold{fold}_best.pth\"\n","      ) # scibertでの変更\n","  check_point = torch.load(model_dir +CONFIG.exp + \"/\"+ f\"{CONFIG.model_name.split('/')[1]}_fold{fold}_best.pth\")\n","\n","  valid_folds[\"preds\"] = check_point[\"preds\"]\n","\n","  return valid_folds,best_borders"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RkzBmBnLBv86"},"source":["def get_result(result_df):\n","    preds = result_df[\"preds\"].values\n","    labels = result_df[\"judgement\"].values\n","    best_threshold = opt_fbeta_threshold(labels, preds)\n","    print(\"Best_Threshold：\" + str(best_threshold))\n","    # 上実行すると、ValueError: Classification metrics can't handle a mix of continuous and binary targets\n","    score = fbeta_score(labels, np.where(preds < best_threshold, 0, 1), beta=7.0)\n","    print(\"Score：\" + str(score))\n","    LOGGER.info(f\"Score: {score:<.5f}\")\n","\n","# inference用に、best_thresholdを出力するようにする関数\n","def get_result_for_cv(result_df,best_border):\n","    preds = result_df[\"preds\"].values\n","    labels = result_df[\"judgement\"].values\n","    #best_threshold = opt_fbeta_threshold(labels, preds)\n","    print(\"Best_Threshold：\" + str(best_border))\n","    # 上実行すると、ValueError: Classification metrics can't handle a mix of continuous and binary targets\n","    score = fbeta_score(labels, np.where(preds < best_border, 0, 1), beta=7.0)\n","    LOGGER.info(f\"Score: {score:<.5f}\")\n","\n","    return score\n","\n","def mean_best_border(*best_borders):\n","    best_border = np.mean(best_borders)\n","    print(\"Best_Threshold：\" + str(best_border))\n","    LOGGER.info(f\"Best_Border: {best_border:<.8f}\")\n","\n","    return best_border"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9mZGKRQADebR","executionInfo":{"elapsed":6,"status":"ok","timestamp":1630507864712,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"},"user_tz":-540},"outputId":"8a7554d2-882f-4538-8f7c-f9f32c96aaa6"},"source":["def remove_non_alphabetic(texts):\n","    text_list=[]\n","\n","    for text in texts: \n","        text = re.sub(r\"[^a-zA-Z]\", \" \", text)\n","        text = text.replace(\"  \", \" \")\n","        text_list.append(text)\n","    return text_list\n","\n","\n","nltk.download('stopwords')\n","stop_words = stopwords.words('english')\n","\n","def clean_stopword(text_list):\n","    texts_temp= [[word for word in text.lower().split() if word not in stop_words] for text in text_list]\n","    return texts_temp\n","\n","\n","def split_copyright(texts):\n","\n","    text_list=[]\n","\n","    for text in texts:    \n","\n","        if \"Copyright\" in text:\n","            text = text.split('Copyright')[0]\n","            text_list.append(text)\n","        else:\n","            text_list.append(text)\n","    return text_list\n","\n","nlp = spacy.load('en', disable=['parser', 'ner'])\n","\n","def lemmatization(texts_list, allowed_postags=['PROPN','VERB','NOUN','ADJ', 'ADV']):\n","   \n","    texts_pre=[]\n","\n","    for sent in texts_list:\n","        doc = nlp(\" \".join(sent)) \n","        texts_pre.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n","    return texts_pre\n","\n","def preprocess_text(text):\n","    text = remove_non_alphabetic(text)\n","    text = split_copyright(text)\n","    text = clean_stopword(text)\n","    #text = lemmatization(text)\n","    \n","    return text\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","metadata":{"id":"NeRaL5mh-ozs"},"source":["pd.set_option(\"display.max_colwidth\", 50)\n","#train = pd.read_csv(input_dir + \"train.csv\")\n","train = pd.read_pickle(input_dir+\"train_rev1.pkl\")\n","test = pd.read_csv(input_dir + \"test.csv\")\n","sub = pd.read_csv(input_dir + \"sample_submit.csv\", header=None)\n","sub.columns = [\"id\", \"judgement\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"5pLNyTCB-po5","executionInfo":{"elapsed":12,"status":"ok","timestamp":1630507868373,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"},"user_tz":-540},"outputId":"d0b766a3-e740-4db1-f009-76dbefefb9e2"},"source":["train = get_train_data(train)\n","train.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>judgement</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Comparative analysis of the main haematologica...</td>\n","      <td>BACKGROUND: Severe acute respiratory syndrome ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Validation of an optimized SPM procedure for F...</td>\n","      <td>Diagnostic accuracy in FDG-PET imaging highly ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Is SARSCoV-2 nasopharyngeal swab still a gold ...</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Title: Utility of Repeat Testing for COVID-19:...</td>\n","      <td>As the Coronavirus disease 2019 continues to c...</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Performance of VivaDiagTM COVID-19 IgM/IgG Rap...</td>\n","      <td>From late December 2019 COVID-19 (Coronavirus ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                              title  ... judgement  fold\n","0   0  Comparative analysis of the main haematologica...  ...         1     4\n","1   1  Validation of an optimized SPM procedure for F...  ...         1     4\n","2   2  Is SARSCoV-2 nasopharyngeal swab still a gold ...  ...         1     0\n","3   3  Title: Utility of Repeat Testing for COVID-19:...  ...         1     4\n","4   4  Performance of VivaDiagTM COVID-19 IgM/IgG Rap...  ...         1     4\n","\n","[5 rows x 5 columns]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"H36lHBpwcJz3","executionInfo":{"elapsed":425,"status":"ok","timestamp":1630507868792,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"},"user_tz":-540},"outputId":"ce8db145-c344-4fe6-b673-899d7e1d9408"},"source":["train[\"title_abst\"] = train[\"title\"] + train[\"abstract\"]\n","train[\"title_abst\"].fillna(train[\"title\"], inplace=True)\n","\n","test[\"title_abst\"] = test[\"title\"] + test[\"abstract\"]\n","test[\"title_abst\"].fillna(test[\"title\"], inplace=True)\n","\n","train.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>judgement</th>\n","      <th>fold</th>\n","      <th>title_abst</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Comparative analysis of the main haematologica...</td>\n","      <td>BACKGROUND: Severe acute respiratory syndrome ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>Comparative analysis of the main haematologica...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Validation of an optimized SPM procedure for F...</td>\n","      <td>Diagnostic accuracy in FDG-PET imaging highly ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>Validation of an optimized SPM procedure for F...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Is SARSCoV-2 nasopharyngeal swab still a gold ...</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Is SARSCoV-2 nasopharyngeal swab still a gold ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Title: Utility of Repeat Testing for COVID-19:...</td>\n","      <td>As the Coronavirus disease 2019 continues to c...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>Title: Utility of Repeat Testing for COVID-19:...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Performance of VivaDiagTM COVID-19 IgM/IgG Rap...</td>\n","      <td>From late December 2019 COVID-19 (Coronavirus ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>Performance of VivaDiagTM COVID-19 IgM/IgG Rap...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ...                                         title_abst\n","0   0  ...  Comparative analysis of the main haematologica...\n","1   1  ...  Validation of an optimized SPM procedure for F...\n","2   2  ...  Is SARSCoV-2 nasopharyngeal swab still a gold ...\n","3   3  ...  Title: Utility of Repeat Testing for COVID-19:...\n","4   4  ...  Performance of VivaDiagTM COVID-19 IgM/IgG Rap...\n","\n","[5 rows x 6 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"LGYn-iQhTy9u"},"source":["title_abst_train= train.title_abst\n","title_abst_test = test.title_abst\n","\n","title_abst_train= preprocess_text(title_abst_train)\n","title_abst_test = preprocess_text(title_abst_test)\n","\n","# preprocess\n","train[\"title_abst\"] = title_abst_train\n","test[\"title_abst\"] = title_abst_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkKHrVztDPUW"},"source":["# titleの単語数が3以下のものは除外してみる\n","train[\"title_word_len\"] = train[\"title\"].str.split(\" \").str.len()\n","train = train[train[\"title_word_len\"]>3]\n","\n","# titleが他言語の場合は除外\n","train[\"title_lang\"] = train[\"title\"].fillna(\"\").map(lambda x: cld2.detect(x)[2][0][1])\n","train = train[(train[\"title_lang\"]==\"en\")|(train[\"title_lang\"]==\"un\")]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oHee5M4_kIVv"},"source":["#train.to_pickle(input_dir+\"train_pre.pkl\")\n","#test.to_pickle(input_dir+\"test_pre.pkl\")\n","#train = pd.read_pickle(input_dir+\"train_pre.pkl\")\n","#test = pd.read_pickle(input_dir+\"test_pre.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_xbubAoknLE"},"source":["#BERTに入力する用にスペース区切りに戻す\n","def reverse(x):\n","    x = \" \". join([str(i) for i in list(x)])\n","    return x\n","\n","train[\"title_abst\"] = train[\"title_abst\"].apply(lambda x : reverse(x))\n","test[\"title_abst\"] = test[\"title_abst\"].apply(lambda x : reverse(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":200},"id":"0lY2xUY7vBst","executionInfo":{"elapsed":11,"status":"ok","timestamp":1630507902353,"user":{"displayName":"KAZUKI HIRAHARA","photoUrl":"","userId":"09073430568031937610"},"user_tz":-540},"outputId":"fbbe26c2-9552-42c0-ea0a-bf1d263f70c9"},"source":["train.head()"],"execution_count":null,"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>abstract</th>\n","      <th>judgement</th>\n","      <th>fold</th>\n","      <th>title_abst</th>\n","      <th>title_word_len</th>\n","      <th>title_lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Comparative analysis of the main haematologica...</td>\n","      <td>BACKGROUND: Severe acute respiratory syndrome ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>comparative analysis main haematological index...</td>\n","      <td>16</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Validation of an optimized SPM procedure for F...</td>\n","      <td>Diagnostic accuracy in FDG-PET imaging highly ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>validation optimized spm procedure fdg pet dem...</td>\n","      <td>15</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Is SARSCoV-2 nasopharyngeal swab still a gold ...</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>sarscov nasopharyngeal swab still gold standar...</td>\n","      <td>10</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Title: Utility of Repeat Testing for COVID-19:...</td>\n","      <td>As the Coronavirus disease 2019 continues to c...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>title utility repeat testing covid lab steward...</td>\n","      <td>14</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Performance of VivaDiagTM COVID-19 IgM/IgG Rap...</td>\n","      <td>From late December 2019 COVID-19 (Coronavirus ...</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>performance vivadiagtm covid igm igg rapid tes...</td>\n","      <td>21</td>\n","      <td>en</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ... title_lang\n","0   0  ...         en\n","1   1  ...         en\n","2   2  ...         en\n","3   3  ...         en\n","4   4  ...         en\n","\n","[5 rows x 8 columns]"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["bd3893e53a7749d880f64c176eb23611","5f62e21bc6b44c3c983d254a8ebaa92d","072111c03c1c4882a3f499f9be2c17ed","e9924a4393e64c0eb8f5e03768f680e5","ff7a72323a5b4c73ad4e4380b1ef38d9","903cbf5d65e5457a9c7374aa72bf694b","dec83bce8306464d9bde019c260d9f88","a6019c8841014ac9ab5209aa8928c707","17132604c6f24c9c8abdf065c670cde3","f195b06d559c48f7abe292e484868a8c","315f45cde21a46ca91617696bf1b083f","823fe6be14b9436ebb46761f6962144d","73b6cee40e194042ad12e11abb68c20c","ac62dafe1ef34bf8b493a99d82313334","e37a56082ae84e3a8b8327b9d1f66748","f9f7747188b6401da4245032fb26ea3a","56c2d2892f1246a080a29b5767624563","cc588f7fe9654eafb134176e9212aa62","a41ea72a0b49478d9aff0e8e828184d3","4db8c1893c104271a15011cfcc499041","b1001c7a955f43d6bfe63e4f40ff7e5a","3df8f318e62049beb44439f7c5625679","aeb18fb851c94f16b983164d35e12196","451cc38684fb483ebd7b7123c68694d1","a051dfdfbfaa412099faa82589fa0fec","85c2bece609446bc96806a4d6aaa6c13","fd8bc4c0e22b4c1aa6cbb196553a5d88","8bc08788f4154bbbbf72e191a1da0484","60f3ab5bdbea4963ab6f8fb033bb6790","a279d13943d74a0a88119106d7dcec65","86430e65883841b7b8e38ab4d1d5d4a4","2444f387b79041e4ad12399920fb8ce9","c78448b500114d8483c25d30a0cee4d3"]},"id":"n8wvJSraCIIi","outputId":"9c7d7a75-4dc8-47f3-bb59-50cadd3f4bd3"},"source":["# Training\n","#border = len(train[train[\"judgement\"] == 1]) / len(train[\"judgement\"]) # 0.023245467689912133\n","#border = border * 0.6\n","\n","mean_border_folds = []\n"," \n","oof_df = pd.DataFrame()\n","for fold in range(CONFIG.fold):\n","  _oof_df,best_borders = train_loop(train, fold)\n","  oof_df = pd.concat([oof_df, _oof_df])\n","  LOGGER.info(f\"========== fold: {fold} result ==========\")\n","  best_border_fold = mean_best_border(best_borders)\n","  mean_border_folds.append(best_border_fold)\n","        \n","# CV result\n","LOGGER.info(f\"========== CV ==========\")\n","best_border = mean_best_border(mean_border_folds)\n","get_result_for_cv(oof_df,best_border)\n","    \n","# Save OOF result\n","oof_df.to_csv(pred_dir +CONFIG.exp + \"/oof_df.csv\", index=False)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd3893e53a7749d880f64c176eb23611","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/225k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"823fe6be14b9436ebb46761f6962144d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/462 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aeb18fb851c94f16b983164d35e12196","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/1346] Elapsed 0m 0s (remain 14m 15s) Loss: 0.7333 \n","Epoch: [1][100/1346] Elapsed 0m 25s (remain 5m 18s) Loss: 0.1097 \n","Epoch: [1][200/1346] Elapsed 0m 51s (remain 4m 52s) Loss: 0.0971 \n","Epoch: [1][300/1346] Elapsed 1m 16s (remain 4m 26s) Loss: 0.0969 \n","Epoch: [1][400/1346] Elapsed 1m 41s (remain 4m 0s) Loss: 0.0942 \n","Epoch: [1][500/1346] Elapsed 2m 7s (remain 3m 34s) Loss: 0.0859 \n","Epoch: [1][600/1346] Elapsed 2m 32s (remain 3m 9s) Loss: 0.0834 \n","Epoch: [1][700/1346] Elapsed 2m 58s (remain 2m 43s) Loss: 0.0815 \n","Epoch: [1][800/1346] Elapsed 3m 23s (remain 2m 18s) Loss: 0.0781 \n","Epoch: [1][900/1346] Elapsed 3m 49s (remain 1m 53s) Loss: 0.0770 \n","Epoch: [1][1000/1346] Elapsed 4m 14s (remain 1m 27s) Loss: 0.0749 \n","Epoch: [1][1100/1346] Elapsed 4m 39s (remain 1m 2s) Loss: 0.0729 \n","Epoch: [1][1200/1346] Elapsed 5m 5s (remain 0m 36s) Loss: 0.0714 \n","Epoch: [1][1300/1346] Elapsed 5m 30s (remain 0m 11s) Loss: 0.0707 \n","Epoch: [1][1345/1346] Elapsed 5m 42s (remain 0m 0s) Loss: 0.0709 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 58s)Loss: 0.7560\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 11s)Loss: 0.0682\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0709  avg_val_loss: 0.0553  time: 370s\n","Epoch 1 - Score: 0.8443568815085842\n","Epoch 1 - Save Best Score: 0.8444 \n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0553\n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","Best_Border: 0.04603268\n","========== fold: 1 training ==========\n"]},{"name":"stdout","output_type":"stream","text":["Best_Threshold：0.046032683216487694\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/1345] Elapsed 0m 0s (remain 10m 15s) Loss: 0.7496 \n","Epoch: [1][100/1345] Elapsed 0m 25s (remain 5m 17s) Loss: 0.1346 \n","Epoch: [1][200/1345] Elapsed 0m 51s (remain 4m 51s) Loss: 0.1191 \n","Epoch: [1][300/1345] Elapsed 1m 16s (remain 4m 25s) Loss: 0.1123 \n","Epoch: [1][400/1345] Elapsed 1m 42s (remain 4m 0s) Loss: 0.1056 \n","Epoch: [1][500/1345] Elapsed 2m 7s (remain 3m 34s) Loss: 0.1006 \n","Epoch: [1][600/1345] Elapsed 2m 32s (remain 3m 9s) Loss: 0.0928 \n","Epoch: [1][700/1345] Elapsed 2m 58s (remain 2m 43s) Loss: 0.0863 \n","Epoch: [1][800/1345] Elapsed 3m 23s (remain 2m 18s) Loss: 0.0851 \n","Epoch: [1][900/1345] Elapsed 3m 49s (remain 1m 52s) Loss: 0.0807 \n","Epoch: [1][1000/1345] Elapsed 4m 14s (remain 1m 27s) Loss: 0.0798 \n","Epoch: [1][1100/1345] Elapsed 4m 39s (remain 1m 2s) Loss: 0.0778 \n","Epoch: [1][1200/1345] Elapsed 5m 5s (remain 0m 36s) Loss: 0.0770 \n","Epoch: [1][1300/1345] Elapsed 5m 30s (remain 0m 11s) Loss: 0.0745 \n","Epoch: [1][1344/1345] Elapsed 5m 41s (remain 0m 0s) Loss: 0.0741 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 56s)Loss: 1.5874\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 11s)Loss: 0.0763\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0741  avg_val_loss: 0.0561  time: 369s\n","Epoch 1 - Score: 0.8551167964404894\n","Epoch 1 - Save Best Score: 0.8551 \n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0561\n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 1 result ==========\n","Best_Border: 0.01276950\n","========== fold: 2 training ==========\n"]},{"name":"stdout","output_type":"stream","text":["Best_Threshold：0.012769502946374649\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/1346] Elapsed 0m 0s (remain 10m 8s) Loss: 0.7999 \n","Epoch: [1][100/1346] Elapsed 0m 25s (remain 5m 16s) Loss: 0.1260 \n","Epoch: [1][200/1346] Elapsed 0m 51s (remain 4m 50s) Loss: 0.1089 \n","Epoch: [1][300/1346] Elapsed 1m 16s (remain 4m 25s) Loss: 0.0997 \n","Epoch: [1][400/1346] Elapsed 1m 41s (remain 3m 59s) Loss: 0.0936 \n","Epoch: [1][500/1346] Elapsed 2m 7s (remain 3m 34s) Loss: 0.0898 \n","Epoch: [1][600/1346] Elapsed 2m 32s (remain 3m 9s) Loss: 0.0867 \n","Epoch: [1][700/1346] Elapsed 2m 57s (remain 2m 43s) Loss: 0.0834 \n","Epoch: [1][800/1346] Elapsed 3m 23s (remain 2m 18s) Loss: 0.0803 \n","Epoch: [1][900/1346] Elapsed 3m 48s (remain 1m 52s) Loss: 0.0786 \n","Epoch: [1][1000/1346] Elapsed 4m 14s (remain 1m 27s) Loss: 0.0779 \n","Epoch: [1][1100/1346] Elapsed 4m 39s (remain 1m 2s) Loss: 0.0778 \n","Epoch: [1][1200/1346] Elapsed 5m 4s (remain 0m 36s) Loss: 0.0760 \n","Epoch: [1][1300/1346] Elapsed 5m 30s (remain 0m 11s) Loss: 0.0734 \n","Epoch: [1][1345/1346] Elapsed 5m 41s (remain 0m 0s) Loss: 0.0734 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 57s)Loss: 0.8411\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 11s)Loss: 0.0708\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0734  avg_val_loss: 0.0603  time: 369s\n","Epoch 1 - Score: 0.8448324415657559\n","Epoch 1 - Save Best Score: 0.8448 \n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0603\n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 2 result ==========\n","Best_Border: 0.05139041\n","========== fold: 3 training ==========\n"]},{"name":"stdout","output_type":"stream","text":["Best_Threshold：0.051390410557255885\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/1346] Elapsed 0m 0s (remain 10m 10s) Loss: 0.5239 \n","Epoch: [1][100/1346] Elapsed 0m 25s (remain 5m 16s) Loss: 0.1260 \n","Epoch: [1][200/1346] Elapsed 0m 50s (remain 4m 50s) Loss: 0.1033 \n","Epoch: [1][300/1346] Elapsed 1m 16s (remain 4m 24s) Loss: 0.0975 \n","Epoch: [1][400/1346] Elapsed 1m 41s (remain 3m 59s) Loss: 0.0935 \n","Epoch: [1][500/1346] Elapsed 2m 7s (remain 3m 34s) Loss: 0.0907 \n","Epoch: [1][600/1346] Elapsed 2m 32s (remain 3m 8s) Loss: 0.0846 \n","Epoch: [1][700/1346] Elapsed 2m 57s (remain 2m 43s) Loss: 0.0811 \n","Epoch: [1][800/1346] Elapsed 3m 23s (remain 2m 18s) Loss: 0.0801 \n","Epoch: [1][900/1346] Elapsed 3m 48s (remain 1m 52s) Loss: 0.0785 \n","Epoch: [1][1000/1346] Elapsed 4m 14s (remain 1m 27s) Loss: 0.0773 \n","Epoch: [1][1100/1346] Elapsed 4m 39s (remain 1m 2s) Loss: 0.0747 \n","Epoch: [1][1200/1346] Elapsed 5m 4s (remain 0m 36s) Loss: 0.0731 \n","Epoch: [1][1300/1346] Elapsed 5m 30s (remain 0m 11s) Loss: 0.0731 \n","Epoch: [1][1345/1346] Elapsed 5m 41s (remain 0m 0s) Loss: 0.0725 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 56s)Loss: 1.6214\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 11s)Loss: 0.0753\n","EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0560\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0725  avg_val_loss: 0.0560  time: 369s\n","Epoch 1 - Score: 0.8117345485616633\n","Epoch 1 - Save Best Score: 0.8117 \n","========== fold: 3 result ==========\n","Best_Border: 0.03642896\n","========== fold: 4 training ==========\n"]},{"name":"stdout","output_type":"stream","text":["Best_Threshold：0.03642895707929356\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/1345] Elapsed 0m 0s (remain 10m 18s) Loss: 0.6523 \n","Epoch: [1][100/1345] Elapsed 0m 25s (remain 5m 16s) Loss: 0.1162 \n","Epoch: [1][200/1345] Elapsed 0m 51s (remain 4m 50s) Loss: 0.0981 \n","Epoch: [1][300/1345] Elapsed 1m 16s (remain 4m 25s) Loss: 0.0926 \n","Epoch: [1][400/1345] Elapsed 1m 41s (remain 3m 59s) Loss: 0.0840 \n","Epoch: [1][500/1345] Elapsed 2m 7s (remain 3m 34s) Loss: 0.0860 \n","Epoch: [1][600/1345] Elapsed 2m 32s (remain 3m 9s) Loss: 0.0823 \n","Epoch: [1][700/1345] Elapsed 2m 58s (remain 2m 43s) Loss: 0.0800 \n","Epoch: [1][800/1345] Elapsed 3m 23s (remain 2m 18s) Loss: 0.0769 \n","Epoch: [1][900/1345] Elapsed 3m 49s (remain 1m 52s) Loss: 0.0754 \n","Epoch: [1][1000/1345] Elapsed 4m 14s (remain 1m 27s) Loss: 0.0730 \n","Epoch: [1][1100/1345] Elapsed 4m 39s (remain 1m 2s) Loss: 0.0741 \n","Epoch: [1][1200/1345] Elapsed 5m 5s (remain 0m 36s) Loss: 0.0736 \n","Epoch: [1][1300/1345] Elapsed 5m 30s (remain 0m 11s) Loss: 0.0729 \n","Epoch: [1][1344/1345] Elapsed 5m 41s (remain 0m 0s) Loss: 0.0713 \n","EVAL: [0/169]Elapsed 0m 0s (remain 0m 56s)Loss: 0.9903\n","EVAL: [100/169]Elapsed 0m 16s (remain 0m 11s)Loss: 0.0633\n","EVAL: [168/169]Elapsed 0m 27s (remain 0m 0s)Loss: 0.0462\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.0713  avg_val_loss: 0.0462  time: 370s\n","Epoch 1 - Score: 0.8708795163379875\n","Epoch 1 - Save Best Score: 0.8709 \n","========== fold: 4 result ==========\n","Best_Border: 0.01925098\n","========== CV ==========\n","Best_Border: 0.03317451\n","Score: 0.82601\n"]},{"name":"stdout","output_type":"stream","text":["Best_Threshold：0.019250978633173165\n","Best_Threshold：0.033174506486516986\n","Best_Threshold：0.033174506486516986\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"wsmKzZM8fhSc","outputId":"af9afcab-968b-492e-8805-ed88a1dfe098"},"source":["best_border"],"execution_count":null,"outputs":[{"data":{"text/plain":["0.033174506486516986"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"vn-D60_1CVgv","outputId":"53be5636-8e13-4e88-d9b6-78bd97395639"},"source":["# inference, submit\n","# border を出力できるようにしたい\n","#best_border = 0.017733983065538965\n","predictions = inference()\n","\n","# stacking用にpredictionを保存\n","pred_df = pd.DataFrame()\n","pred_df[\"id\"] = test[\"id\"]\n","pred_df[\"judgement\"] = predictions\n","pred_df.to_csv(pred_dir +CONFIG.exp + \"/pred_df.csv\", index=False)\n","\n","predictions = np.where(predictions < best_border, 0, 1)\n","\n","# submission\n","sub[\"judgement\"] = predictions\n","sub.to_csv(submission_dir +CONFIG.exp+ \"_submission.csv\", index=False, header=False)"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["========== model: GanjinZero/UMLSBert_ENG fold: 0 inference ==========\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:26<00:00,  6.17it/s]\n","========== model: GanjinZero/UMLSBert_ENG fold: 1 inference ==========\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:27<00:00,  6.15it/s]\n","========== model: GanjinZero/UMLSBert_ENG fold: 2 inference ==========\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:27<00:00,  6.17it/s]\n","========== model: GanjinZero/UMLSBert_ENG fold: 3 inference ==========\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:27<00:00,  6.15it/s]\n","========== model: GanjinZero/UMLSBert_ENG fold: 4 inference ==========\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GanjinZero/UMLSBert_ENG and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","100%|██████████| 1277/1277 [03:27<00:00,  6.15it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"SNKnI9WhPGCb"},"source":[" "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"119E27NX1zLL"},"source":[""],"execution_count":null,"outputs":[]}]}